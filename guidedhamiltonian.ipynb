{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Geometry-Guided Quantum SAT Solver\n# Copyright (c) 2025, Sabarikirishwaran Ponnambalam\n#\n# This software is licensed under the Polyform Noncommercial License.\n# See the LICENSE file in the project root for full license terms.\n\n!pip install --no-cache-dir torch torchvision torchaudio -q\n!pip install --no-cache-dir custatevec-cu12 cudaq -q\n!pip install --no-cache-dir pandas numpy matplotlib geoopt -q\n# !pip install --no-cache-dir pytorch-lightning -q\n# !pip install --no-cache-dir lightning pennylane-lightning-gpu -q\n# !pip install --no-cache-dir \"jax[cuda12]\" pennylane-catalyst -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Full state simulation for small scale","metadata":{}},{"cell_type":"code","source":"# Geometry-Guided Quantum SAT Solver\n\nimport math\nimport itertools\n\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\n\nimport geoopt\nfrom typing import List, Tuple\nimport matplotlib.pyplot as plt\n\n\n# Clause type\nClause = List[Tuple[int, bool]]\nFormula = List[Clause]\n\ndef generate_random_3sat(n_vars: int, n_clauses: int) -> Formula:\n    formula = []\n    for _ in range(n_clauses):\n        clause_vars = np.random.choice(n_vars, 3, replace=False)\n        clause = [(int(v), bool(np.random.randint(2))) for v in clause_vars]\n        formula.append(clause)\n    return formula\n\ndef eval_clause(bits: Tuple[int], clause: Clause) -> bool:\n    return any((bits[v] ^ is_neg) for v, is_neg in clause)\n\ndef basis_states(n: int) -> List[Tuple[int]]:\n    return list(itertools.product([0, 1], repeat=n))\n\n# Clause projector\ndef clause_projector(n: int, clause: Clause) -> torch.Tensor:\n    dim = 2 ** n\n    P = torch.zeros((dim, dim), dtype=torch.cdouble)\n    for i, bits in enumerate(basis_states(n)):\n        if eval_clause(bits, clause):\n            P[i, i] = 1.0\n    return P\n\ndef full_solution_projector(n: int, formula: Formula) -> torch.Tensor:\n    dim = 2 ** n\n    P = torch.zeros((dim, dim), dtype=torch.cdouble)\n    for i, bits in enumerate(basis_states(n)):\n        if all(eval_clause(bits, c) for c in formula):\n            P[i, i] = 1.0\n    return P\n\ndef fubini_study_angle(psi: torch.Tensor, phi: torch.Tensor) -> float:\n    overlap = torch.abs(torch.vdot(psi, phi))\n    return float(torch.acos(torch.clamp(overlap, 0.0, 1.0)))\n\n# Geometry-guided unitary optimization on St(d,d)\ndef optimize_unitary_stiefel(psi: torch.Tensor, P: torch.Tensor, \n                              lr=0.1, steps=100) -> Tuple[torch.Tensor, List[float]]:\n    d = psi.shape[0]\n    manifold = geoopt.manifolds.Stiefel()\n    U = geoopt.ManifoldParameter(torch.eye(d, dtype=torch.cdouble), manifold=manifold)\n    optimizer = torch.optim.SGD([U], lr=lr)\n    overlaps = []\n\n    for _ in range(steps):\n        optimizer.zero_grad()\n        UHU = U.conj().T @ P @ U\n        overlap = torch.vdot(psi, UHU @ psi).real\n        loss = -overlap\n        loss.backward()\n        optimizer.step()\n        overlaps.append(overlap.item())\n\n    return U.detach(), overlaps\n\n# Measurement & projection\ndef project_and_normalize(psi: torch.Tensor, P: torch.Tensor) -> Tuple[torch.Tensor, float]:\n    p = torch.vdot(psi, P @ psi).real.item()\n    if p < 1e-12:\n        return psi, 0.0\n    psi_proj = P @ psi / torch.sqrt(torch.tensor(p, dtype=torch.float64))\n    return psi_proj, p\n\n# Solver\ndef geometry_guided_solver(n: int, formula: Formula, steps=50, lr=0.1, verbose=False):\n    dim = 2 ** n\n    psi = torch.ones(dim, dtype=torch.cdouble) / math.sqrt(dim)\n    projectors = [clause_projector(n, c) for c in formula]\n    P_solution = full_solution_projector(n, formula)\n\n    total_p = 1.0\n    fs_angles = []\n\n    for P in tqdm(projectors):\n        U, _ = optimize_unitary_stiefel(psi, P, lr=lr, steps=steps)\n        psi_rot = U @ psi\n        psi, p_clause = project_and_normalize(psi_rot, P)\n        total_p *= p_clause\n        fs_angle = fubini_study_angle(psi, (P_solution @ psi) / torch.linalg.norm(P_solution @ psi))\n        fs_angles.append(fs_angle)\n        if verbose:\n            print(f\"Clause success: {p_clause:.6f}, Fubini–Study angle: {fs_angle:.4f} rad\")\n        if p_clause < 1e-6:\n            break\n\n    return {\n        \"final_state\": psi,\n        \"success_prob\": total_p,\n        \"fubini_angles\": fs_angles,\n        \"overlap_solution\": torch.vdot(psi, P_solution @ psi).real.item()\n    }\n\n# Time-to-solution\ndef time_to_solution(p_success: float, t_run: float, p_target=0.99) -> float:\n    if p_success <= 0.0:\n        return float(\"inf\")\n    if p_success >= 1.0:\n        return t_run\n    num_runs = math.log(1 - p_target) / math.log(1 - p_success)\n    return t_run * num_runs\n\n# Baselines (nonguided + classical)\ndef nonguided_measurement_solver(n: int, formula: Formula):\n    dim = 2 ** n\n    psi = torch.ones(dim, dtype=torch.cdouble) / math.sqrt(dim)\n    total_p = 1.0\n    for clause in formula:\n        P = clause_projector(n, clause)\n        p_clause = torch.vdot(psi, P @ psi).real.item()\n        psi, _ = project_and_normalize(psi, P)\n        total_p *= p_clause\n    return total_p\n\n# Benchmarking setup\ndef benchmark_experiment(n: int, m: int, trials=10):\n    geo_scores = []\n    nonguided_scores = []\n    fs_logs = []\n    for _ in range(trials):\n        formula = generate_random_3sat(n, m)\n        res = geometry_guided_solver(n, formula, steps=30, lr=0.1)\n        geo_scores.append(res[\"success_prob\"])\n        fs_logs.append(res[\"fubini_angles\"])\n        nonguided = nonguided_measurement_solver(n, formula)\n        nonguided_scores.append(nonguided)\n\n    print(\"Geometry-guided avg success:\", np.mean(geo_scores))\n    print(\"Non-guided baseline avg success:\", np.mean(nonguided_scores))\n    return geo_scores, nonguided_scores, fs_logs\n\nif __name__ == \"__main__\":\n    n = 12\n    m = 6\n    geo_scores, nonguided_scores, fs_logs = benchmark_experiment(n, m, trials=5)\n\n    plt.figure(figsize=(8, 4))\n    for angles in fs_logs:\n        plt.plot(angles, label='Fubini–Study angle')\n    plt.xlabel(\"Clause step\")\n    plt.ylabel(\"Fubini–Study angle (rad)\")\n    plt.title(\"Geometric evolution of state vs solution space\")\n    plt.grid()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Quantum Parametric Circuit","metadata":{}},{"cell_type":"code","source":"\"\"\"\nGeometry-guided 3-SAT solver with CUDA-Q (cuQuantum backend) and Riemannian\noptimization over a parametric circuit's angles (theta).\n\nThis follows the specification described in the chat:\n- 3-SAT -> diagonal SAT Hamiltonian\n- parametric ansatz U(theta) defined as CUDA-Q kernel\n- statevector simulation on GPU (cuQuantum)\n- geometric flag regularizer + Fubini–Study smoothness regularizer\n- Riemannian optimization over theta using geoopt with finite-diff gradients\n\"\"\"\n\nimport math\nimport time\nimport itertools\nfrom typing import List, Tuple, Dict, Any\n\nimport numpy as np\nimport torch\nimport geoopt\n\nimport cudaq\nfrom tqdm.auto import tqdm \n\n# --------------------------------------------------------------------\n# SAT encoding\n# --------------------------------------------------------------------\n\nClause = List[Tuple[int, bool]]\nFormula = List[Clause]\n\n\ndef generate_random_3sat(n_vars: int, n_clauses: int) -> Formula:\n    \"\"\"Random 3-SAT instance with distinct vars per clause.\"\"\"\n    formula: Formula = []\n    for _ in range(n_clauses):\n        clause_vars = np.random.choice(n_vars, 3, replace=False)\n        clause: Clause = [(int(v), bool(np.random.randint(2))) for v in clause_vars]\n        formula.append(clause)\n    return formula\n\n\ndef eval_clause(bits: Tuple[int, ...], clause: Clause) -> bool:\n    \"\"\"\n    Evaluate a single clause on a bitstring.\n    bits[i] in {0,1}; clause is list of (var_index, is_negated).\n\n    Interpretation:\n      literal = x if is_negated == False,\n                (NOT x) if is_negated == True\n    \"\"\"\n    # clause satisfied iff any literal is True.\n    for var_idx, is_neg in clause:\n        val = bits[var_idx]\n        if is_neg:\n            lit_val = 1 - val  # NOT\n        else:\n            lit_val = val\n        if lit_val == 1:\n            return True\n    return False\n\n\ndef bits_from_int(i: int, n: int) -> Tuple[int, ...]:\n    \"\"\"Convert integer to n-bit tuple (big-endian: qubit 0 is MSB).\"\"\"\n    return tuple((i >> (n - 1 - j)) & 1 for j in range(n))\n\n# --------------------------------------------------------------------\n# SAT Hamiltonian\n# --------------------------------------------------------------------\n\ndef precompute_sat_data(n: int, formula: Formula):\n    \"\"\"\n    For given n and formula, precompute:\n      - energies: length 2^n, energies[i] = # of unsatisfied clauses\n      - sat_masks: shape (m, 2^n), sat_masks[k, i] True if assignment i\n                   satisfies clauses 0..k (inclusive).\n      - basis_strings: all bitstrings '000..0' .. '111..1', to feed cudaq.\n    \"\"\"\n    num_states = 1 << n\n    m = len(formula)\n\n    energies = np.zeros(num_states, dtype=np.float64)\n    sat_masks = np.zeros((m, num_states), dtype=bool)\n    basis_strings = [format(i, f\"0{n}b\") for i in range(num_states)]\n\n    for idx in range(num_states):\n        bits = bits_from_int(idx, n)\n        clause_satisfied = [eval_clause(bits, c) for c in formula]\n        unsat = m - sum(clause_satisfied)\n        energies[idx] = float(unsat)\n\n        # Flag masks: satisfy first k+1 clauses\n        running_ok = True\n        for k in range(m):\n            if running_ok and clause_satisfied[k]:\n                sat_masks[k, idx] = True\n            else:\n                running_ok = False\n                # No need to set sat_masks[k..] further; they remain False.\n\n    return energies, sat_masks, basis_strings\n\n# --------------------------------------------------------------------\n# CUDA-Q kernel for parametric ansatz U(theta)\n# --------------------------------------------------------------------\n\n@cudaq.kernel\ndef sat_ansatz(params: list[float], n_qubits: int):\n    \"\"\"\n    Parametric ansatz:\n      - Start from |0..0>\n      - Apply H on each qubit (-> |+>^n)\n      - depth layers of (RY, RZ) per qubit + CNOT chain entanglers\n\n    params length must be 2 * n_qubits * depth.\n    depth = len(params) // (2 * n_qubits).\n    \"\"\"\n    q = cudaq.qvector(n_qubits)\n\n    # Prepare reference state |+>^n\n    for i in range(n_qubits):\n        h(q[i])\n\n    depth = int(len(params) // (2 * n_qubits))\n    idx = 0\n    for _ in range(depth):\n        # Single-qubit rotations\n        for i in range(n_qubits):\n            ry(params[idx], q[i])\n            idx += 1\n            rz(params[idx], q[i])\n            idx += 1\n        # Entangling layer: CNOT chain\n        for i in range(n_qubits - 1):\n            x.ctrl(q[i], q[i + 1])\n\ndef prepare_state(theta: np.ndarray, n_qubits: int) -> cudaq.State:\n    \"\"\"\n    Run CUDA-Q statevector simulation for given theta and n_qubits.\n    Returns a cudaq.State living on GPU (cuQuantum backend).\n    \"\"\"\n    theta_list = theta.tolist()\n    state = cudaq.get_state(sat_ansatz, theta_list, n_qubits)\n    return state\n\n# --------------------------------------------------------------------\n# Geometry guided loss and regularizers\n# --------------------------------------------------------------------\n\ndef evaluate_loss(\n    theta: np.ndarray,\n    n: int,\n    formula: Formula,\n    energies: np.ndarray,\n    sat_masks: np.ndarray,\n    basis_strings: List[str],\n    prev_state: cudaq.State | None,\n    lambda_flag: float = 0.1,\n    lambda_smooth: float = 0.01,\n) -> Tuple[float, Dict[str, Any], cudaq.State]:\n    \"\"\"\n    Compute loss and metrics at given theta.\n\n    Returns:\n      loss (scalar)\n      metrics dict\n      current cudaq.State\n    \"\"\"\n    m = len(formula)\n    state = prepare_state(theta, n)\n\n    # basis state amplitudes\n    amps = np.array(state.amplitudes(basis_strings), dtype=np.complex128)\n    probs = np.abs(amps) ** 2\n\n    # objective\n    E = float(np.dot(probs, energies))  # expectation of frac. of not-sat. clauses\n    main_loss = E / m if m > 0 else 0.0\n    sat_prob = 1.0 - main_loss if m > 0 else 0.0\n\n    # Flag regularizer: FS angle to subspaces satisfying first k clauses\n    m_clauses = sat_masks.shape[0]\n    flag_terms: List[float] = []\n    for k in range(m_clauses):\n        p_k = float(probs[sat_masks[k]].sum())\n        p_k = max(0.0, min(1.0, p_k))\n        if p_k <= 0.0:\n            theta_fs_k = math.pi / 2.0\n        else:\n            theta_fs_k = math.acos(math.sqrt(p_k))\n        flag_terms.append(theta_fs_k ** 2)\n    R_flag = float(sum(flag_terms) / m_clauses) if m_clauses > 0 else 0.0\n\n    # Smoothness regularizer: FS angle to previous state\n    R_smooth = 0.0\n    fs_angle_prev = None\n    if prev_state is not None:\n        overlap = state.overlap(prev_state)\n        val = abs(overlap)\n        val = max(0.0, min(1.0, val))\n        fs_angle_prev = math.acos(val)\n        R_smooth = fs_angle_prev ** 2\n\n    loss = main_loss + lambda_flag * R_flag + lambda_smooth * R_smooth\n\n    metrics = {\n        \"loss\": loss,\n        \"main_loss\": main_loss,\n        \"E\": E,\n        \"sat_prob\": sat_prob,\n        \"R_flag\": R_flag,\n        \"R_smooth\": R_smooth,\n        \"theta_fs_prev\": fs_angle_prev,\n    }\n    return loss, metrics, state\n\n\ndef finite_difference_grad(\n    theta: np.ndarray,\n    loss_fn,\n    eps: float = 1e-2,\n) -> np.ndarray:\n    \"\"\"\n    Central finite-difference gradient for scalar loss_fn(theta).\n\n    loss_fn: callable(theta: np.ndarray) -> float\n    \"\"\"\n    grad = np.zeros_like(theta, dtype=np.float64)\n    for i in range(theta.size):\n        theta_plus = theta.copy()\n        theta_minus = theta.copy()\n        theta_plus[i] += eps\n        theta_minus[i] -= eps\n\n        lp = loss_fn(theta_plus)\n        lm = loss_fn(theta_minus)\n        grad[i] = (lp - lm) / (2.0 * eps)\n    return grad\n\n\n# --------------------------------------------------------------------\n# Riemannian optimization\n# --------------------------------------------------------------------\n\ndef optimize_geometry_guided_sat(\n    n: int,\n    formula: Formula,\n    depth: int = 1,\n    max_iters: int = 20,\n    lr: float = 0.1,\n    lambda_flag: float = 0.1,\n    lambda_smooth: float = 0.01,\n    verbose: bool = True,\n) -> Tuple[np.ndarray, List[Dict[str, Any]], float]:\n    \"\"\"\n    Geometry-guided SAT solver logic\n\n    Returns:\n      best_theta (numpy array)\n      history (list of metric dicts)\n      total_run_time (seconds)\n    \"\"\"\n    # Set CUDA-Q target to GPU/cuQuantum if available\n    try:\n        cudaq.set_target(\"nvidia\")\n    except Exception:\n        try:\n            cudaq.set_target(\"cuquantum\")\n        except Exception: # Fallback: let CUDA-Q choose default simulator\n            pass\n\n    str_tm_SATprecomp = time.time()\n    energies, sat_masks, basis_strings = precompute_sat_data(n, formula)\n    end_tm_SATprecomp = time.time()\n\n    print(\"SAT precompute data exec. time: \", (end_tm_SATprecomp - str_tm_SATprecomp))\n\n    num_params = 2 * n * depth\n    manifold = geoopt.manifolds.Euclidean()\n    theta = geoopt.ManifoldParameter(\n        torch.zeros(num_params, dtype=torch.float64), manifold=manifold\n    )\n    optimizer = geoopt.optim.RiemannianAdam([theta], lr=lr)\n\n    history: List[Dict[str, Any]] = []\n    prev_state: cudaq.State | None = None\n    best_theta = None\n    best_sat_prob = -1.0\n\n    start_time = time.perf_counter()\n        \n    iter_range = range(max_iters)\n    if verbose:\n        iter_range = tqdm(iter_range, desc=\"Optimization\", unit=\"iter\")\n    \n    #Optimization loop\n    for it in iter_range:\n        optimizer.zero_grad(set_to_none=True)\n\n        # Current parameter\n        theta_np = theta.detach().cpu().numpy().astype(np.float64)\n\n        # loss_fn (fix prev_state for this iteration)\n        def loss_fn_local(vec: np.ndarray) -> float:\n            l, _, _ = evaluate_loss(\n                vec,\n                n,\n                formula,\n                energies,\n                sat_masks,\n                basis_strings,\n                prev_state=prev_state,\n                lambda_flag=lambda_flag,\n                lambda_smooth=lambda_smooth,\n            )\n            return l\n\n        # Evaluate base loss\n        base_loss, metrics, state = evaluate_loss(\n            theta_np,\n            n,\n            formula,\n            energies,\n            sat_masks,\n            basis_strings,\n            prev_state=prev_state,\n            lambda_flag=lambda_flag,\n            lambda_smooth=lambda_smooth,\n        )\n\n        # Estimate gradient\n        grad_np = finite_difference_grad(theta_np, loss_fn_local, eps=1e-2)\n        theta.grad = torch.from_numpy(grad_np).to(theta)\n\n        optimizer.step()\n\n        prev_state = state\n        history.append(metrics)\n\n        if metrics[\"sat_prob\"] > best_sat_prob:\n            best_sat_prob = metrics[\"sat_prob\"]\n            best_theta = theta_np.copy()\n\n        if verbose:\n            if isinstance(iter_range, tqdm):\n                iter_range.set_postfix(\n                    loss=f\"{metrics['loss']:.4f}\",\n                    sat=f\"{metrics['sat_prob']:.4f}\",\n                    Rf=f\"{metrics['R_flag']:.3f}\",\n                    Rs=f\"{metrics['R_smooth']:.3f}\",\n                )\n            else:\n                print(\n                    f\"[Iter {it:02d}] \"\n                    f\"loss={metrics['loss']:.4f}, \"\n                    f\"sat_prob={metrics['sat_prob']:.4f}, \"\n                    f\"R_flag={metrics['R_flag']:.4f}, \"\n                    f\"R_smooth={metrics['R_smooth']:.4f}\"\n                )\n\n    total_time = time.perf_counter() - start_time\n    return best_theta, history, total_time\n\n\n# --------------------------------------------------------------------\n# TTS logic\n# --------------------------------------------------------------------\n\ndef time_to_solution(p_success: float, t_run: float, p_target: float = 0.99) -> float:\n    \"\"\"\n    Expected time to achieve overall success probability >= p_target,\n    assuming independent repeats with per-run success p_success and\n    runtime t_run per run.\n    \"\"\"\n    if p_success <= 0.0:\n        return float(\"inf\")\n    if p_success >= 1.0:\n        return t_run\n    num_runs = math.log(1.0 - p_target) / math.log(1.0 - p_success)\n    return t_run * num_runs\n\n# --------------------------------------------------------------------\n# Driver\n# --------------------------------------------------------------------\nif __name__ == \"__main__\":    \n    n = 18  # no.of. variables\n    m = 91  # no.of. clauses to satisfy\n    depth = 1\n\n    formula = generate_random_3sat(n, m)\n    print(f\"Generated random 3-SAT with n={n}, m={m}\")\n\n    best_theta, hist, total_time = optimize_geometry_guided_sat(\n        n,\n        formula,\n        depth=depth,\n        max_iters=50,      \n        lr=0.1,\n        lambda_flag=0.1,\n        lambda_smooth=0.01,\n        verbose=True,\n    )\n\n    final_metrics = hist[-1]\n    p_success = final_metrics[\"sat_prob\"]\n    tts_est = time_to_solution(p_success, total_time, p_target=0.99)\n\n    print(\"\\n=== Summary ===\")\n    print(f\"Final sat_prob ≈ {p_success:.4f}\")\n    print(f\"Total runtime (single run) ≈ {total_time:.3f} s\")\n    print(f\"Estimated TTS (p_target=0.99) ≈ {tts_est:.3f} s\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Upgraded","metadata":{}}]}